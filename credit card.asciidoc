+*In[5]:*+
[source, ipython3]
----
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils import resample

data = pd.read_csv(r"C:\Users\Lenovo\Desktop\creditcard.csv")
data.head()

print(data['Class'].value_counts()) 
data_majority = data[data.Class == 0]
data_minority = data[data.Class == 1]
data_majority_downsampled = resample(data_majority, 
                                     replace=False,    
                                     n_samples=len(data_minority), 
                                     random_state=42)  
data_balanced = pd.concat([data_majority_downsampled, data_minority])
print(data_balanced['Class'].value_counts())

X = data_balanced.drop('Class', axis=1)
y = data_balanced['Class']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

----


+*Out[5]:*+
----
Class
0    284315
1       492
Name: count, dtype: int64
Class
0    492
1    492
Name: count, dtype: int64
Confusion Matrix:
[[95  4]
 [11 87]]

Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.96      0.93        99
           1       0.96      0.89      0.92        98

    accuracy                           0.92       197
   macro avg       0.93      0.92      0.92       197
weighted avg       0.93      0.92      0.92       197

----


+*In[ ]:*+
[source, ipython3]
----

----
